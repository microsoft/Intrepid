from learning.core_learner.abstract_rl_discrete_latent_state import (
    AbstractRLDiscreteLatentState,
)
from learning.learning_utils.encoder_sampler_ik import EncoderSamplerIK
from learning.learning_utils.ik_train_encoding_function import IKTrainEncodingFunction



class IDLearning(AbstractRLDiscreteLatentState):
    """
    An algorithm similar to Homer but that instead relies on inverse kinematics:
            max_\theta p(a_h | x_h, \phi(x_{h+1}))
    """

    def __init__(self, exp_setup):
        super(IDLearning, self).__init__(exp_setup)

        self.config = exp_setup.config
        self.constants = exp_setup.constants
        self.logger = exp_setup.logger
        self.experiment = exp_setup.experiment
        self.actions = self.config["actions"]

        # Train encoding function
        self.train_encoder = IKTrainEncodingFunction(self.config, self.constants)

        # Sampler for generating data for training the encoding function
        self.encoder_sampler = EncoderSamplerIK()

    def gather_dataset(self, env, step, homing_policies, num_samples, dataset):
        """
        Collect a set of dataset given the environment. Return a tuple of:
            - dataset which can be arbitrary and used by the specific implementation to train the dataset
            - list of episodes generated by the agent in the process
        Any implementation needs to implement this.
        """

        dataset = self.encoder_sampler.gather_samples(
            num_samples, env, self.actions, step, homing_policies
        )
        return dataset, dataset

    def train_discrete_encoder(
        self,
        dataset,
        logger,
        tensorboard,
        debug,
        bootstrap_model,
        undiscretized_initialization=True,
    ):
        """
        Returns:
            - encoding_function: a function that maps an observation to one of the s values where s is a natural number
            - num_state_budget: the natural number s
        """

        encoding_function, num_state_budget = self.train_encoder.train_model(
            dataset=dataset,
            logger=self.logger,
            tensorboard=tensorboard,
            discretized=True,
            bootstrap_model=None,
        )

        return encoding_function, num_state_budget
